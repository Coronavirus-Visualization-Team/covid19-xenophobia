{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('filename')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# FILENAME = args.filename\n",
    "FILENAME = \"all_xeno_v2.tsv\"\n",
    "df = pd.DataFrame([], columns=['id', 'date', 'full_text'])\n",
    "# df.to_csv('filtered_' + FILENAME, encoding='utf-8', index=False)\n",
    "df.to_csv('filtered.csv', encoding='utf-8', index=False)\n",
    "\n",
    "reader = pd.read_csv(FILENAME, encoding='utf-8', parse_dates=['tweet_date'], delimiter='\\t', usecols=['tweet_date', 'tweet_id_str', 'tweet_full_text'],chunksize=10000)\n",
    "p.set_options(p.OPT.URL)\n",
    "\n",
    "for chunk in reader:\n",
    "    chunk = chunk.fillna('')\n",
    "    filtered = chunk\n",
    "#     filtered = chunk[chunk['full_text'].str.contains('china|chinese|asia|asian|chinazi|chink|chingchong|gook', flags=re.IGNORECASE, regex=True)]\n",
    "    for i, row in filtered.iterrows():\n",
    "        filtered.at[i, 'tweet_full_text'] = p.clean(row['tweet_full_text'])\n",
    "#         print(row['full_text'])\n",
    "    filtered.to_csv('filtered.csv', mode='a', encoding='utf-8', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
